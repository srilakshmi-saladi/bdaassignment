{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "Retinal Vessel Segmentation with U-Net",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/srilakshmi-saladi/bdaassignment/blob/main/Retinal_Vessel_Segmentation_with_U_Net.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "import kagglehub\n",
        "ipythonx_retinal_vessel_segmentation_path = kagglehub.dataset_download('ipythonx/retinal-vessel-segmentation')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "BpfbUdUWJn-Z"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U -q segmentation-models --user\n",
        "\n",
        "from PIL import Image\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "os.environ[\"SM_FRAMEWORK\"] = \"tf.keras\"\n",
        "\n",
        "import segmentation_models as sm\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow_io as tfio\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "root = '../input/retinal-vessel-segmentation'\n",
        "exts = ('jpg', 'JPG', 'png', 'PNG', 'tif', 'gif', 'ppm')"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-04-24T10:17:31.595827Z",
          "iopub.status.busy": "2022-04-24T10:17:31.594303Z",
          "iopub.status.idle": "2022-04-24T10:17:46.660611Z",
          "shell.execute_reply": "2022-04-24T10:17:46.660049Z",
          "shell.execute_reply.started": "2022-04-24T09:48:31.844105Z"
        },
        "papermill": {
          "duration": 15.083498,
          "end_time": "2022-04-24T10:17:46.660782",
          "exception": false,
          "start_time": "2022-04-24T10:17:31.577284",
          "status": "completed"
        },
        "tags": [],
        "id": "Fk6mwIO3Jn-a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DRIVE\n",
        "\n",
        "The dataset comes with pair of input retina image and target mask. Among all retina image, we will only use this dataset for a quick baseline. However, rest of the dataset can be replaces easily on this pipeline.\n"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.012155,
          "end_time": "2022-04-24T10:17:46.687613",
          "exception": false,
          "start_time": "2022-04-24T10:17:46.675458",
          "status": "completed"
        },
        "tags": [],
        "id": "8ZaOANIdJn-a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_data = os.path.join(root, 'DRIVE/training/images')\n",
        "images = sorted(\n",
        "    [\n",
        "        os.path.join(input_data, fname)\n",
        "        for fname in os.listdir(input_data)\n",
        "        if fname.endswith(exts) and not fname.startswith(\".\")\n",
        "    ]\n",
        ")\n",
        "\n",
        "\n",
        "target_data = os.path.join(root, 'DRIVE/training/1st_manual')\n",
        "masks = sorted(\n",
        "    [\n",
        "        os.path.join(target_data, fname)\n",
        "        for fname in os.listdir(target_data)\n",
        "        if fname.endswith(exts) and not fname.startswith(\".\")\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(\"Number of samples:\", len(images), len(masks))\n",
        "for input_path, target_path in zip(images[:10], masks[:10]):\n",
        "    print(input_path[-31:], \"|\", target_path[-34:])"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-04-24T10:17:46.719293Z",
          "iopub.status.busy": "2022-04-24T10:17:46.718778Z",
          "iopub.status.idle": "2022-04-24T10:17:46.744533Z",
          "shell.execute_reply": "2022-04-24T10:17:46.744069Z",
          "shell.execute_reply.started": "2022-04-24T09:48:47.207825Z"
        },
        "papermill": {
          "duration": 0.044689,
          "end_time": "2022-04-24T10:17:46.744663",
          "exception": false,
          "start_time": "2022-04-24T10:17:46.699974",
          "status": "completed"
        },
        "tags": [],
        "id": "FNCSZ2cSJn-b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IMAGE_SIZE = 512\n",
        "BATCH_SIZE = 12\n",
        "\n",
        "def read_files(image_path, mask=False):\n",
        "    image = tf.io.read_file(image_path)\n",
        "    if mask:\n",
        "        image = tf.io.decode_gif(image) # out: (1, h, w, 3)\n",
        "        image = tf.squeeze(image) # out: (h, w, 3)\n",
        "        image = tf.image.rgb_to_grayscale(image) # out: (h, w, 1)\n",
        "        image = tf.divide(image, 128)\n",
        "        image.set_shape([None, None, 1])\n",
        "        image = tf.image.resize(images=image, size=[IMAGE_SIZE, IMAGE_SIZE])\n",
        "        image = tf.cast(image, tf.int32)\n",
        "    else:\n",
        "        image = tfio.experimental.image.decode_tiff(image) # out: (h, w, 4)\n",
        "        image = image[:,:,:3] # out: (h, w, 3)\n",
        "        image.set_shape([None, None, 3])\n",
        "        image = tf.image.resize(images=image, size=[IMAGE_SIZE, IMAGE_SIZE])\n",
        "        image = image / 255.\n",
        "    return image\n",
        "\n",
        "def load_data(image_list, mask_list):\n",
        "    image = read_files(image_list)\n",
        "    mask  = read_files(mask_list, mask=True)\n",
        "    return image, mask\n",
        "\n",
        "def data_generator(image_list, mask_list):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((image_list, mask_list))\n",
        "    dataset = dataset.map(load_data, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    dataset = dataset.batch(BATCH_SIZE, drop_remainder=False)\n",
        "    return dataset\n",
        "\n",
        "train_dataset = data_generator(images, masks)\n",
        "train_dataset"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-04-24T10:17:48.869885Z",
          "iopub.status.busy": "2022-04-24T10:17:48.567578Z",
          "iopub.status.idle": "2022-04-24T10:17:49.308336Z",
          "shell.execute_reply": "2022-04-24T10:17:49.308762Z",
          "shell.execute_reply.started": "2022-04-24T09:48:47.263574Z"
        },
        "papermill": {
          "duration": 2.551456,
          "end_time": "2022-04-24T10:17:49.308912",
          "exception": false,
          "start_time": "2022-04-24T10:17:46.757456",
          "status": "completed"
        },
        "tags": [],
        "id": "beqMB1YNJn-b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize(**images):\n",
        "    \"\"\"PLot images in one row.\"\"\"\n",
        "    n = len(images)\n",
        "    plt.figure(figsize=(20, 20))\n",
        "    for i, (name, image) in enumerate(images.items()):\n",
        "        plt.subplot(1, n, i + 1)\n",
        "        plt.xticks([])\n",
        "        plt.yticks([])\n",
        "        plt.title(' '.join(name.split('_')).title())\n",
        "        plt.imshow(image, cmap='gray')\n",
        "    plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-04-24T10:17:49.340789Z",
          "iopub.status.busy": "2022-04-24T10:17:49.340253Z",
          "iopub.status.idle": "2022-04-24T10:17:49.343464Z",
          "shell.execute_reply": "2022-04-24T10:17:49.343078Z",
          "shell.execute_reply.started": "2022-04-24T09:48:50.007141Z"
        },
        "papermill": {
          "duration": 0.021677,
          "end_time": "2022-04-24T10:17:49.343566",
          "exception": false,
          "start_time": "2022-04-24T10:17:49.321889",
          "status": "completed"
        },
        "tags": [],
        "id": "7E9oQXDXJn-c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image, mask = next(iter(train_dataset.take(1)))\n",
        "print(image.shape, mask.shape)\n",
        "\n",
        "for (img, msk) in zip(image[:5], mask[:5]):\n",
        "    print(mask.numpy().min(), mask.numpy().max())\n",
        "    print(np.unique(mask.numpy()))\n",
        "    visualize(\n",
        "        image=img.numpy(),\n",
        "        gt_mask=msk.numpy(),\n",
        "    )"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-04-24T10:17:49.374596Z",
          "iopub.status.busy": "2022-04-24T10:17:49.374096Z",
          "iopub.status.idle": "2022-04-24T10:17:52.933106Z",
          "shell.execute_reply": "2022-04-24T10:17:52.933512Z",
          "shell.execute_reply.started": "2022-04-24T09:48:50.015026Z"
        },
        "papermill": {
          "duration": 3.577321,
          "end_time": "2022-04-24T10:17:52.933666",
          "exception": false,
          "start_time": "2022-04-24T10:17:49.356345",
          "status": "completed"
        },
        "tags": [],
        "id": "Y3v2ch46Jn-c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build and train our neural network\n",
        "\n",
        "\n",
        "![](https://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/u-net-architecture.png)"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.072129,
          "end_time": "2022-04-24T10:17:53.078461",
          "exception": false,
          "start_time": "2022-04-24T10:17:53.006332",
          "status": "completed"
        },
        "tags": [],
        "id": "CYgUsyN8Jn-c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build U-Net model\n",
        "inputs = Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n",
        "s = Lambda(lambda x: x / 255) (inputs)\n",
        "s = inputs\n",
        "c1 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (s)\n",
        "c1 = Dropout(0.1) (c1)\n",
        "c1 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c1)\n",
        "p1 = MaxPooling2D((2, 2)) (c1)\n",
        "\n",
        "c2 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p1)\n",
        "c2 = Dropout(0.1) (c2)\n",
        "c2 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c2)\n",
        "p2 = MaxPooling2D((2, 2)) (c2)\n",
        "\n",
        "c3 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p2)\n",
        "c3 = Dropout(0.2) (c3)\n",
        "c3 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c3)\n",
        "p3 = MaxPooling2D((2, 2)) (c3)\n",
        "\n",
        "c4 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p3)\n",
        "c4 = Dropout(0.2) (c4)\n",
        "c4 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c4)\n",
        "p4 = MaxPooling2D(pool_size=(2, 2)) (c4)\n",
        "\n",
        "c5 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p4)\n",
        "c5 = Dropout(0.3) (c5)\n",
        "c5 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c5)\n",
        "\n",
        "u6 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same') (c5)\n",
        "u6 = concatenate([u6, c4])\n",
        "c6 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u6)\n",
        "c6 = Dropout(0.2) (c6)\n",
        "c6 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c6)\n",
        "\n",
        "u7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same') (c6)\n",
        "u7 = concatenate([u7, c3])\n",
        "c7 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u7)\n",
        "c7 = Dropout(0.2) (c7)\n",
        "c7 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c7)\n",
        "\n",
        "u8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c7)\n",
        "u8 = concatenate([u8, c2])\n",
        "c8 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u8)\n",
        "c8 = Dropout(0.1) (c8)\n",
        "c8 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c8)\n",
        "\n",
        "u9 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (c8)\n",
        "u9 = concatenate([u9, c1], axis=3)\n",
        "c9 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u9)\n",
        "c9 = Dropout(0.1) (c9)\n",
        "c9 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c9)\n",
        "\n",
        "outputs = Conv2D(1, (1, 1), activation='sigmoid') (c9)\n",
        "\n",
        "model = Model(inputs=[inputs], outputs=[outputs])\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[mean_iou])\n",
        "model.summary()"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.071228,
          "end_time": "2022-04-24T10:17:53.221187",
          "exception": false,
          "start_time": "2022-04-24T10:17:53.149959",
          "status": "completed"
        },
        "tags": [],
        "id": "8QH6VHv7Jn-d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "\n",
        "# Free up RAM in case the model definition cells were run multiple times\n",
        "keras.backend.clear_session()\n",
        "BACKBONE   = 'efficientnetb0'\n",
        "n_classes  = 1\n",
        "activation = 'sigmoid'\n",
        "model = sm.Unet(BACKBONE, classes=n_classes, activation=activation)\n",
        "# model.summary(line_length=110)"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-04-24T10:17:53.371879Z",
          "iopub.status.busy": "2022-04-24T10:17:53.37093Z",
          "iopub.status.idle": "2022-04-24T10:17:56.465224Z",
          "shell.execute_reply": "2022-04-24T10:17:56.464739Z",
          "shell.execute_reply.started": "2022-04-24T09:48:53.171687Z"
        },
        "papermill": {
          "duration": 3.17252,
          "end_time": "2022-04-24T10:17:56.465353",
          "exception": false,
          "start_time": "2022-04-24T10:17:53.292833",
          "status": "completed"
        },
        "tags": [],
        "id": "pSZ2F5v-Jn-d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Callback : Monitoring Training Progress"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.076538,
          "end_time": "2022-04-24T10:17:56.618833",
          "exception": false,
          "start_time": "2022-04-24T10:17:56.542295",
          "status": "completed"
        },
        "tags": [],
        "id": "j4i5ZdfaJn-e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DisplayCallback(keras.callbacks.Callback):\n",
        "    def __init__(self, dataset, epoch_interval=50):\n",
        "        self.dataset = dataset\n",
        "        self.epoch_interval = epoch_interval\n",
        "\n",
        "    def display(self, display_list, extra_title=''):\n",
        "        plt.figure(figsize=(15, 15))\n",
        "        title = ['Input Image', 'True Mask', 'Predicted Mask']\n",
        "\n",
        "        if len(display_list) > len(title):\n",
        "            title.append(extra_title)\n",
        "\n",
        "        for i in range(len(display_list)):\n",
        "            plt.subplot(1, len(display_list), i+1)\n",
        "            plt.title(title[i])\n",
        "            plt.imshow(display_list[i], cmap='gray')\n",
        "            plt.axis('off')\n",
        "        plt.show()\n",
        "\n",
        "    def create_mask(self, pred_mask):\n",
        "        pred_mask = (pred_mask > 0.5).astype(\"int32\")\n",
        "        return pred_mask[0]\n",
        "\n",
        "    def show_predictions(self, dataset, num=1):\n",
        "        for image, mask in dataset.take(num):\n",
        "            pred_mask = model.predict(image)\n",
        "            self.display([image[0], mask[0], self.create_mask(pred_mask)])\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        if epoch and epoch % self.epoch_interval == 0:\n",
        "            self.show_predictions(self.dataset)\n",
        "            print ('\\nSample Prediction after epoch {}\\n'.format(epoch+1))"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-04-24T10:17:56.781921Z",
          "iopub.status.busy": "2022-04-24T10:17:56.781155Z",
          "iopub.status.idle": "2022-04-24T10:17:56.783729Z",
          "shell.execute_reply": "2022-04-24T10:17:56.783283Z",
          "shell.execute_reply.started": "2022-04-24T09:48:55.99282Z"
        },
        "papermill": {
          "duration": 0.089301,
          "end_time": "2022-04-24T10:17:56.783846",
          "exception": false,
          "start_time": "2022-04-24T10:17:56.694545",
          "status": "completed"
        },
        "tags": [],
        "id": "-2V50_YOJn-e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Compile and Fit"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.077044,
          "end_time": "2022-04-24T10:17:56.936039",
          "exception": false,
          "start_time": "2022-04-24T10:17:56.858995",
          "status": "completed"
        },
        "tags": [],
        "id": "5AaFUAt5Jn-e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define optomizer\n",
        "optim = keras.optimizers.Adam(0.0001)\n",
        "bce   = keras.losses.BinaryCrossentropy()\n",
        "metrics = [\"accuracy\"]\n",
        "\n",
        "# compile keras model with defined optimozer, loss and metrics\n",
        "model.compile(optim, bce, metrics)\n",
        "\n",
        "model.fit(\n",
        "    train_dataset,\n",
        "    callbacks=[DisplayCallback(train_dataset)],\n",
        "    epochs=400\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-04-24T10:17:57.103329Z",
          "iopub.status.busy": "2022-04-24T10:17:57.102356Z",
          "iopub.status.idle": "2022-04-24T10:27:39.366965Z",
          "shell.execute_reply": "2022-04-24T10:27:39.366501Z",
          "shell.execute_reply.started": "2022-04-24T09:48:56.006122Z"
        },
        "papermill": {
          "duration": 582.354663,
          "end_time": "2022-04-24T10:27:39.367115",
          "exception": false,
          "start_time": "2022-04-24T10:17:57.012452",
          "status": "completed"
        },
        "tags": [],
        "id": "DGCnEipCJn-e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('seg.h5')\n",
        "# model.save_weights('./seg.h5')"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-04-24T10:27:40.597469Z",
          "iopub.status.busy": "2022-04-24T10:27:40.596445Z",
          "iopub.status.idle": "2022-04-24T10:27:41.447767Z",
          "shell.execute_reply": "2022-04-24T10:27:41.446841Z",
          "shell.execute_reply.started": "2022-04-24T10:05:25.911125Z"
        },
        "papermill": {
          "duration": 1.475859,
          "end_time": "2022-04-24T10:27:41.447911",
          "exception": false,
          "start_time": "2022-04-24T10:27:39.972052",
          "status": "completed"
        },
        "tags": [],
        "id": "zxdypYgQJn-f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "papermill": {
          "duration": 0.611051,
          "end_time": "2022-04-24T10:27:42.675311",
          "exception": false,
          "start_time": "2022-04-24T10:27:42.06426",
          "status": "completed"
        },
        "tags": [],
        "id": "I-X0aKl9Jn-f"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}